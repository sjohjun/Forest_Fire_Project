{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas_gbq\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import lxml\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster, HeatMap\n",
    "\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, shape\n",
    "from shapely import wkt\n",
    "\n",
    "import googlemaps\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "KEY_PATH = \"config/\"\n",
    "\n",
    "key_path = KEY_PATH + \"fireforest-team-ys-2023.json\"\n",
    "servicekey_path = KEY_PATH + \"serviceKey.json\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_key(servicekey_path, key_name):\n",
    "    \"\"\"\n",
    "    주어진 서비스 키 파일에서 지정된 키 이름에 해당하는 서비스 키를 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        servicekey_path (str): 서비스 키 파일의 경로.\n",
    "        key_name (str): 반환할 서비스 키의 이름.\n",
    "\n",
    "    Returns:\n",
    "        str or None: 지정된 키 이름에 해당하는 서비스 키. 키를 찾을 수 없는 경우 None을 반환합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(servicekey_path) as f:\n",
    "        data = json.load(f)\n",
    "        service_key = data.get(key_name)\n",
    "    return service_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_bigquery(df, dataset_id, table_id, key_path):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임을 BigQuery 테이블에 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): 저장할 데이터프레임.\n",
    "        dataset_id (str): 대상 데이터셋의 ID.\n",
    "        table_id (str): 대상 테이블의 ID.\n",
    "        key_path (str): 서비스 계정 키 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Credentials 객체 생성\n",
    "    credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "    # 빅쿼리 클라이언트 객체 생성\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # 테이블 레퍼런스 생성\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # 데이터프레임을 BigQuery 테이블에 적재\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition = \"WRITE_TRUNCATE\"  # 기존 테이블 내용 삭제 후 삽입\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
    "    job.result()  # 작업 완료 대기\n",
    "\n",
    "    print(f\"Data inserted into table {table_id} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bigquery(dataset_id, table_id, key_path):\n",
    "    \"\"\"\n",
    "    주어진 BigQuery 테이블에서 데이터를 조회하여 DataFrame으로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        dataset_id (str): 대상 데이터셋의 ID.\n",
    "        table_id (str): 대상 테이블의 ID.\n",
    "        key_path (str): 서비스 계정 키 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 조회된 데이터를 담은 DataFrame 객체.\n",
    "    \"\"\"\n",
    "\n",
    "    # Credentials 객체 생성\n",
    "    credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "    # BigQuery 클라이언트 생성\n",
    "    client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "    # 테이블 레퍼런스 생성\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # 테이블 데이터를 DataFrame으로 변환\n",
    "    df = client.list_rows(table_ref).to_dataframe()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geodataframe_to_bigquery(gdf, dataset_id, table_id, key_path):\n",
    "    \"\"\"\n",
    "    주어진 Geopandas GeoDataFrame을 BigQuery 테이블에 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        gdf (geopandas.GeoDataFrame): 저장할 Geopandas GeoDataFrame 객체.\n",
    "        dataset_id (str): 대상 데이터셋의 ID.\n",
    "        table_id (str): 대상 테이블의 ID.\n",
    "        key_path (str): 서비스 계정 키 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "        \n",
    "    gdf = gdf.to_crs('EPSG:4326')\n",
    "    gdf['geometry'] = gdf['geometry'].astype(str)\n",
    "\n",
    "    # Geopandas GeoDataFrame을 Pandas DataFrame으로 변환\n",
    "    df = pd.DataFrame(gdf)\n",
    "\n",
    "    # Credentials 객체 생성\n",
    "    credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "    # 빅쿼리 클라이언트 객체 생성\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # 테이블 레퍼런스 생성\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # 데이터프레임을 BigQuery 테이블에 적재\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition = \"WRITE_TRUNCATE\"  # 기존 테이블 내용 삭제 후 삽입\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
    "    job.result()  # 작업 완료 대기\n",
    "\n",
    "    print(f\"Data inserted into table {table_id} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geodataframe_from_bigquery(dataset_id, table_id, key_path):\n",
    "    \"\"\"\n",
    "    주어진 BigQuery 테이블에서 데이터를 조회하여 Geopandas GeoDataFrame으로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        dataset_id (str): 대상 데이터셋의 ID.\n",
    "        table_id (str): 대상 테이블의 ID.\n",
    "        key_path (str): 서비스 계정 키 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: 조회된 데이터를 담은 Geopandas GeoDataFrame 객체.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Credentials 객체 생성\n",
    "    credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "    # 빅쿼리 클라이언트 객체 생성\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # 쿼리 작성\n",
    "    query = f\"SELECT * FROM `{dataset_id}.{table_id}`\"\n",
    "\n",
    "    # 쿼리 실행\n",
    "    df = client.query(query).to_dataframe()\n",
    "    \n",
    "    # 'geometry' 열의 문자열을 다각형 객체로 변환\n",
    "    df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "\n",
    "    # GeoDataFrame으로 변환\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_days_data(serviceKey, weather_stations, start_date_str=None, end_date_str=None):\n",
    "    \"\"\"\n",
    "    지정한 기상 관측소의 일별 날씨 데이터를 조회하여 데이터프레임으로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        serviceKey (str): 공공데이터포털에서 발급받은 인증키.\n",
    "        weather_stations (pandas.DataFrame): 기상 관측소 정보가 포함된 데이터프레임.\n",
    "        start_date_str (str, optional): 조회 시작 날짜를 나타내는 문자열 (예: \"20220101\").\n",
    "            기본값은 None이며, 기본값일 경우 2013년 1월 1일로 설정됩니다.\n",
    "        end_date_str (str, optional): 조회 끝 날짜를 나타내는 문자열 (예: \"20220331\").\n",
    "            기본값은 None이며, 기본값일 경우 어제 날짜로 설정됩니다.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 조회된 일별 날씨 데이터를 담은 데이터프레임 객체.\n",
    "    \"\"\"\n",
    "        \n",
    "    url = 'http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList'\n",
    "    \n",
    "    # 시작 날짜와 끝 날짜를 생성합니다\n",
    "    if start_date_str is None:\n",
    "        start_date = datetime(2013, 1, 1)  # 시작 날짜를 2013년 1월 1일로 설정합니다\n",
    "    else:\n",
    "        start_date = datetime.strptime(start_date_str, \"%Y%m%d\")\n",
    "    \n",
    "    if end_date_str is None:\n",
    "        end_date = datetime.now() - timedelta(days=1)  # 어제 날짜를 구하기 위해 현재 날짜에서 1일을 뺍니다\n",
    "    else:\n",
    "        end_date = datetime.strptime(end_date_str, \"%Y%m%d\")\n",
    "    \n",
    "    end_date_str = end_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "    all_data = []  # 전체 데이터를 저장할 리스트를 생성합니다\n",
    "\n",
    "    for stnNm in weather_stations[\"stnNm\"]:\n",
    "        params ={\n",
    "            'serviceKey' : serviceKey, \n",
    "            'pageNo' : '1',  # 초기 페이지 번호를 1로 설정합니다\n",
    "            'numOfRows' : '999',  # 한 페이지에 최대로 가져올 데이터 수를 설정합니다\n",
    "            'dataType' : 'json',\n",
    "            'dataCd' : 'ASOS',\n",
    "            'dateCd' : 'DAY',\n",
    "            'startDt' : start_date.strftime(\"%Y%m%d\"),  # 시작 날짜를 문자열로 변환하여 설정합니다\n",
    "            'endDt' : end_date_str,  # 끝 날짜를 어제 날짜로 설정합니다\n",
    "            'stnIds' : stnNm \n",
    "        }\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()  # 오류가 발생하면 예외를 발생시킴\n",
    "                data = response.json()\n",
    "                all_data.extend(data['response']['body']['items']['item'])\n",
    "\n",
    "                # 다음 페이지로 이동\n",
    "                params['pageNo'] = str(int(params['pageNo']) + 1)\n",
    "                if int(params['pageNo']) > int(int(data['response']['body']['totalCount']) / int(params['numOfRows'])) + 1:\n",
    "                    break\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                print(\"API 요청 오류:\", e.response.text)  # API 요청 오류 메시지 출력\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(params)\n",
    "                print(response.content)\n",
    "                print(\"예외 발생:\", e)  # 기타 예외 발생 시 메시지 출력\n",
    "                break\n",
    "\n",
    "    # 리스트에서 데이터프레임을 생성합니다\n",
    "    weather_days = pd.DataFrame(all_data)\n",
    "    \n",
    "    return weather_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forestfire_occurs_data(serviceKey):\n",
    "    \"\"\"\n",
    "    산불 발생 데이터를 조회하여 데이터프레임으로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        serviceKey (str): safemap 에서 발급받은 인증키.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 조회된 산불 발생 데이터를 담은 데이터프레임 객체.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"http://safemap.go.kr/openApiService/data/getFrfireSttusData.do\"\n",
    "    params = {\n",
    "        \"serviceKey\": serviceKey,\n",
    "        \"pageNo\": \"1\",\n",
    "        \"numOfRows\": \"9999\",\n",
    "        \"type\": \"xml\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")  # XML 파싱\n",
    "\n",
    "    columns = [\n",
    "        'objt_id', 'occu_year', 'occu_mt', 'occu_de', 'occu_tm', 'occu_day',\n",
    "        'occu_date', 'end_year', 'end_mt', 'end_de', 'end_tm', 'adres',\n",
    "        'rn_adres', 'resn', 'ar', 'amount', 'ctprvn_cd', 'sgg_cd', 'emd_cd',\n",
    "        'x', 'y'\n",
    "    ]\n",
    "    \n",
    "    data = {}\n",
    "    for column in columns:\n",
    "        data[column] = [element.get_text() for element in soup.find_all(column)]\n",
    "    \n",
    "    forestfire_occurs = pd.DataFrame(data)\n",
    "    \n",
    "    return forestfire_occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forestfire_occurs_add_data(serviceKey):\n",
    "    \"\"\"\n",
    "    산불 추가 발생 데이터를 조회하여 데이터프레임으로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        serviceKey (str): 공공데이터포털에서 발급받은 인증키.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 조회된 산불 추가 발생 데이터를 담은 데이터프레임 객체.\n",
    "    \"\"\"\n",
    "        \n",
    "    url = 'http://apis.data.go.kr/1400000/forestStusService/getfirestatsservice'\n",
    "    \n",
    "    end_date = datetime.now() - timedelta(days=1)\n",
    "    end_date_str = end_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "    params = {\n",
    "        'serviceKey' : serviceKey,\n",
    "        'numOfRows' : '9999',\n",
    "        'pageNo' : '1',\n",
    "        'searchStDt' : '20220101',\n",
    "        'searchEdDt' : end_date_str\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\") #XML 파싱\n",
    "\n",
    "    columns = [\n",
    "        'damagearea', 'endday', 'endmonth', 'endyear', 'firecause', 'locbunji',\n",
    "        'locdong', 'locgungu', 'locmenu', 'locsi', 'startday', 'startdayofweek',\n",
    "        'startmonth', 'starttime', 'startyear'\n",
    "    ]\n",
    "    \n",
    "    data = {}\n",
    "    for column in columns:\n",
    "        data[column] = [element.get_text() for element in soup.find_all(column)]\n",
    "    \n",
    "    forestfire_occurs = pd.DataFrame(data)\n",
    "    \n",
    "    return forestfire_occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataload\n",
    "\n",
    "weather_stations = pd.read_csv(DATA_PATH + \"weather_stations.csv\", encoding=\"cp949\")\n",
    "weather_days = pd.read_csv(DATA_PATH + \"weather_days.csv\", encoding=\"cp949\")\n",
    "\n",
    "forestfire_occurs = pd.read_csv(DATA_PATH + \"forestfire_occurs.csv\", encoding=\"cp949\", dtype=\"object\")\n",
    "forestfire_occurs_add = pd.read_csv(DATA_PATH + \"forestfire_occurs_concat.csv\", encoding=\"cp949\", dtype=\"object\")\n",
    "\n",
    "gangwon_SGG = gpd.read_file(DATA_PATH + \"시군구_강원/LARD_ADM_SECT_SGG_42.shp\", encoding='cp949')\n",
    "gangwon_UMD = gpd.read_file(DATA_PATH + \"읍면동(법정동)_강원/LSMD_ADM_SECT_UMD_42.shp\", encoding='cp949')\n",
    "gangwon_code = pd.read_csv(DATA_PATH + \"gangwon_code.csv\", encoding=\"cp949\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
